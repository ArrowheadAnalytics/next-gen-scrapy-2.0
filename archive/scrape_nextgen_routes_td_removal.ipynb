{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries and functions\n",
    "#!pip install opencv-python\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import json\n",
    "#import urllib\n",
    "import os\n",
    "import urllib.request\n",
    "import cv2\n",
    "import json\n",
    "import scipy.misc\n",
    "import pandas as pd\n",
    "from undistort_field import *\n",
    "from pass_detection import *\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = [\"arizona-cardinals\",\n",
    "\t\"atlanta-falcons\",\n",
    "\t\"baltimore-ravens\",\n",
    "\t\"buffalo-bills\",\n",
    "\t\"carolina-panthers\",\n",
    "\t\"chicago-bears\",\n",
    "\t\"cincinnati-bengals\",\n",
    "\t\"cleveland-browns\",\n",
    "\t\"dallas-cowboys\",\n",
    "\t\"denver-broncos\",\n",
    "\t\"detroit-lions\",\n",
    "\t\"green-bay-packers\",\n",
    "\t\"houston-texans\",\n",
    "\t\"indianapolis-colts\",\n",
    "\t\"jacksonville-jaguars\",\n",
    "\t\"kansas-city-chiefs\",\n",
    "\t\"los-angeles-chargers\",\n",
    "\t\"los-angeles-rams\",\n",
    "\t\"miami-dolphins\",\n",
    "\t\"minnesota-vikings\",\n",
    "\t\"new-england-patriots\",\n",
    "\t\"new-orleans-saints\",\n",
    "\t\"new-york-giants\",\n",
    "\t\"new-york-jets\",\n",
    "\t\"oakland-raiders\",\n",
    "\t\"philadelphia-eagles\",\n",
    "\t\"pittsburgh-steelers\",\n",
    "\t\"san-francisco-49ers\",\n",
    "\t\"seattle-seahawks\",\n",
    "\t\"tampabay-buccaneers\",\n",
    "\t\"tennessee-titans\",\n",
    "\t\"washington-redskins\"\n",
    "]\n",
    "\n",
    "# seasons = [\"2017\",\"2018\",\"2019\"]\n",
    "seasons = ['2019']\n",
    "weeks = [\"1\", \"2\", \"3\", \"4\", \"5\",\n",
    "         \"6\", \"7\", \"8\", \"9\", \"10\",\n",
    "         \"11\", \"12\", \"13\",\n",
    "         '14', \"15\", \"16\", \"17\",\n",
    "         \"wild-card\", \"divisional\",\n",
    "         \"conference\", \"super-bowl\"]\n",
    "\n",
    "pattern = re.compile(\"charts\")\n",
    "\n",
    "print(\"Scraping images and html data...\")\n",
    "\n",
    "for team in teams:\n",
    "\tfor season in seasons:\n",
    "\t\tprint(team, \"\\t\", season)\n",
    "\t\tfor week in weeks:\n",
    "\t\t\tURL = \"https://nextgenstats.nfl.com/charts/list/route/\" + team + \"/\" + season + \"/\" + week\n",
    "\t\t\ttry:\n",
    "\t\t\t\tr = requests.get(URL)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(URL + '  is giving an error. Skipping...')    \n",
    "\t\t\t\tcontinue\n",
    "\t\t\tsoup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "\t\t\tscript = soup.find_all(\"script\", text=pattern)\n",
    "\t\t\tif len(script)==0:\n",
    "\t\t\t\tprint(URL + ' is giving an error. Skipping...')    \n",
    "\t\t\t\tcontinue\n",
    "            \n",
    "\t\t\tcontains_charts = json.loads(str(script[0])[33:-131])\n",
    "\n",
    "\t\t\tif (len(contains_charts[\"charts\"][\"charts\"]) != 0):\n",
    "\t\t\t\tfor chart in contains_charts[\"charts\"][\"charts\"]['charts']:\n",
    "\n",
    "\t\t\t\t\tname = chart[\"lastName\"] + \"_\" + chart[\"firstName\"] + \"_\" + chart[\"position\"]\n",
    "\t\t\t\t\tchart[\"team\"] = team\n",
    "\n",
    "\t\t\t\t\tfolder = str(\"Route_Charts\" + os.sep + team + os.sep + season + os.sep + week + os.sep)\n",
    "\t\t\t\t\timg_folder = folder + \"images\" + os.sep\n",
    "\t\t\t\t\tdata_folder = folder + \"data\" + os.sep\n",
    "\n",
    "\t\t\t\t\tif not os.path.exists(img_folder):\n",
    "\t\t\t\t\t\tos.makedirs(img_folder)\n",
    "\t\t\t\t\tif not os.path.exists(data_folder):\n",
    "\t\t\t\t\t\tos.makedirs(data_folder)\n",
    "\n",
    "\t\t\t\t\timg_file = img_folder + name + \".jpeg\"\n",
    "\t\t\t\t\turl = \"https:\" + chart[\"extraLargeImg\"]\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\turllib.request.urlretrieve(url, img_file)\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tprint(URL + '  is giving an error. Skipping...') \n",
    "\t\t\t\t\t\tcontinue\n",
    "# \t\t\t\t\turllib.request.urlretrieve(url, img_file)\n",
    "\n",
    "\t\t\t\t\tdata_file = data_folder + name + \".txt\"\n",
    "\t\t\t\t\twith open(data_file, 'w') as datafile: \n",
    "\t\t\t\t\t\tjson.dump(chart, datafile)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the images from the charts ('clean.py')\n",
    "def new_image(image):\n",
    "\n",
    "\timg_name = image.split(os.sep)[-1].split(\".\")[0]\n",
    "\timg = cv2.imread(image)\n",
    "\n",
    "\tif (img.shape[0:2] == (1200, 1200)):\n",
    "\t\tcrop_img = img[0:680, 0:1200]\n",
    "\t\ttemp_name = img_name + \"_temp.jpg\"\n",
    "\t\tcv2.imwrite(temp_name, crop_img)\n",
    "\telse:\n",
    "\t\tprint(\"Image must be of size (1200, 1200)\")\n",
    "\t\treturn\n",
    "\n",
    "\tclean_img = clean_field(temp_name)\n",
    "\twrite_path = clean_path + os.sep + os.sep.join(image.split(os.sep)[1:-1]) \n",
    "\tif not os.path.exists(write_path): os.makedirs(write_path)\n",
    "\n",
    "\tif (clean_img != None):\n",
    "\t\twrite_name = write_path + os.sep + img_name + \".jpeg\"\n",
    "\t\tscipy.misc.imsave(write_name, clean_img)\n",
    "\tos.remove(temp_name)\n",
    "\n",
    "def new_data(folder, image): \n",
    "\tdata_path = os.sep.join(folder.split(os.sep)[:-1]) + os.sep + \"data\" \n",
    "\tdata_file = data_path + os.sep + image.split(\".\")[0] + \".txt\"\n",
    "\tif 'St.' in data_file:\n",
    "\t\treturn\n",
    "\tnew_data_path = clean_path + os.sep + os.sep.join(folder.split(os.sep)[1:-1]) + os.sep + \"data\" \n",
    "\tnew_data_file = new_data_path + os.sep + image.split(\".\")[0] + \".txt\"\n",
    "\n",
    "\tif not os.path.exists(new_data_path): \n",
    "\t\tos.makedirs(new_data_path)\n",
    "\n",
    "\twith open(data_file) as _file: \n",
    "\t\told_data = json.load(_file)\n",
    "\t\tnew_data = {key: old_data[key] for key in keys}\n",
    "\twith open(new_data_file, \"w\") as _file:\n",
    "\t\tjson.dump(new_data, _file)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tkeys = ['receptions', 'receivingYards', 'touchdowns', 'playerNameSlug', \n",
    "\t\t'teamId', 'playerName', 'season', 'position',\n",
    "\t\t'type', 'week', 'gameId', 'esbId', 'firstName', 'lastName', \n",
    "\t\t'team'\n",
    "\t]\n",
    "\n",
    "\tclean_path = \"Cleaned_Route_Charts\"\n",
    "\n",
    "\tif not os.path.exists(clean_path): os.makedirs(clean_path)\n",
    "\n",
    "\tpass_chart_folders = [folder[0] for folder in os.walk(\"Route_Charts\")]\n",
    "\timage_folders = [folder for folder in pass_chart_folders if folder.split(os.sep)[-1] == \"images\"]\n",
    "\tprint(\"Cleaning images and data...\")\n",
    "\tfor folder in image_folders:\n",
    "\t\t#print folder \n",
    "\t\timages = os.listdir(folder)\n",
    "\t\tfor image in images:\n",
    "# \t\t\tprint(image)\n",
    "# \t\t\tprint(folder)\n",
    "\t\t\tclean_folder = 'Cleaned_Route_Charts\\'' + folder[12:]            \n",
    "\t\t\tname = os.path.join(clean_folder,image)\n",
    "\t\t\tif os.path.isfile(name):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif not image.startswith(\".\"): \n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tnew_image(os.path.join(folder, image))\n",
    "\t\t\t\t\tnew_data(folder, image)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anyone has ideas to improve this, please do not hesitate to contribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_route_locations(image,td):\n",
    "    lower_green = np.array([40,100, 100])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "\n",
    "    lower_white = np.array([230, 230, 230])\n",
    "    upper_white = np.array([255, 255, 255])\n",
    "\n",
    "    lower_gray = np.array([126, 126, 126])\n",
    "    upper_gray = np.array([132, 132, 132])\n",
    "    col_names = [\"route_type\", \"x\", \"y\"]\n",
    "    route_locations = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    image = cv2.imread(image)\n",
    "    row, col = image.shape[0:2]\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Threshold the HSV image to get only green colors\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    mask2 = cv2.inRange(image, lower_white, upper_white)\n",
    "    mask3 = cv2.inRange(image, lower_gray, upper_gray)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    c_pixels = cv2.bitwise_and(image, image, mask=mask2)\n",
    "    c_pixels = c_pixels.clip(0,1)\n",
    "    ske_c = skeletonize(c_pixels[:,:,1]).astype(np.uint8)\n",
    "    \n",
    "    yac_pixels = cv2.bitwise_and(image, image, mask=mask)\n",
    "    yac_pixels = cv2.cvtColor(yac_pixels, cv2.COLOR_HSV2BGR).clip(0,1)\n",
    "    ske_yac = skeletonize(yac_pixels[:,:,2]).astype(np.uint8)\n",
    "    \n",
    "    inc_pixels = cv2.bitwise_and(image, image, mask=mask3)\n",
    "    inc_pixels = inc_pixels.clip(0,1)\n",
    "    ske_inc = skeletonize(inc_pixels[:,:,1]).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    x,y = np.where(ske_c != 0)\n",
    "    X = np.stack((x,y),axis=1 )\n",
    "    c_routes = X\n",
    "   \n",
    "    x,y = np.where(ske_yac != 0)\n",
    "    X = np.stack((x,y),axis=1 )\n",
    "    yac_routes = X\n",
    "\n",
    "    x,y = np.where(ske_inc != 0)\n",
    "    X = np.stack((x,y),axis=1 )\n",
    "    inc_routes = X\n",
    "\n",
    "\n",
    "    sideline = 40 # pixels\n",
    "    width = 53.33 # standard width of football field\n",
    "    center_x = col/2\n",
    "\n",
    "    if col > 1370:\n",
    "        _75_yd_line = 0\n",
    "        LOS = 596\n",
    "\n",
    "        _1_yd_x = float(col - sideline*2)/width\n",
    "        _1_yd_y = float(LOS - _75_yd_line)/75\n",
    "\n",
    "    else:\n",
    "        _55_yd_line = 5\n",
    "        LOS = 572\n",
    "        _1_yd_x = float(col - sideline*2)/width\n",
    "        _1_yd_y = float(LOS - _55_yd_line)/55\n",
    "\n",
    "    route_type='COMPLETE'\n",
    "    y = c_routes[:,0]\n",
    "    x = c_routes[:,1]\n",
    "    y_loc = (LOS - y)/_1_yd_y\n",
    "    x_loc = (x - center_x)/_1_yd_x\n",
    "    loc = [x_loc,y_loc]\n",
    "    t_loc = np.transpose(loc)\n",
    "    \n",
    "    # TOUCHDOWN REMOVAL CODE\n",
    "    # - Very very crude method of removing TD annotations from\n",
    "    # the charts. If anyone has better ideas (computer vision is likely the way to go here),\n",
    "    #please do not hesitate to reach out\n",
    "    for t in range(0,td):\n",
    "        old_minimum=20\n",
    "        new_points = np.zeros(shape=(102,2))\n",
    "        final_points = new_points.copy()\n",
    "        for i in range(0,275):\n",
    "        #     print(i*.5)\n",
    "            for j in range(0,275):\n",
    "                new_points[:,0] = td_points[:,0]-i*.2\n",
    "                new_points[:,1] = td_points[:,1]+j*.2\n",
    "                C = cdist(t_loc, new_points)\n",
    "                minimum = sum(C.min(axis=0))\n",
    "                if minimum < old_minimum:\n",
    "                    old_minimum=minimum\n",
    "                    td_row, td_col = linear_sum_assignment(C)\n",
    "                    final_points = new_points.copy()\n",
    "        try:\n",
    "            td_row\n",
    "\n",
    "        except:\n",
    "            print('couldn''t find TD')\n",
    "            break\n",
    "\n",
    "        td_rows =list(td_row)\n",
    "        mask = np.ones(len(t_loc), dtype=bool)\n",
    "        mask[td_rows] = False\n",
    "        t_loc = t_loc[mask]\n",
    "    \n",
    "    df = pd.DataFrame(t_loc,columns=['x','y'])\n",
    "    df['route_type'] = route_type\n",
    "    route_locations = route_locations.append(df, ignore_index=True)\n",
    "\n",
    "    route_type='YAC'\n",
    "    y = yac_routes[:,0]\n",
    "    x = yac_routes[:,1]\n",
    "    y_loc = (LOS - y)/_1_yd_y\n",
    "    x_loc = (x - center_x)/_1_yd_x\n",
    "    loc = [x_loc,y_loc]\n",
    "    t_loc = np.transpose(loc)\n",
    "    df = pd.DataFrame(t_loc,columns=['x','y'])\n",
    "    df['route_type'] = route_type\n",
    "    route_locations = route_locations.append(df, ignore_index=True)\n",
    "\n",
    "    route_type='INCOMPLETE'\n",
    "    y = inc_routes[:,0]\n",
    "    x = inc_routes[:,1]\n",
    "    y_loc = (LOS - y)/_1_yd_y\n",
    "    x_loc = (x - center_x)/_1_yd_x\n",
    "    loc = [x_loc,y_loc]\n",
    "    t_loc = np.transpose(loc)\n",
    "    df = pd.DataFrame(t_loc,columns=['x','y'])\n",
    "    df['route_type'] = route_type\n",
    "    route_locations = route_locations.append(df, ignore_index=True)\n",
    "    \n",
    "    return route_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Translate the image data into coordinate data for each chart ('main.py')\n",
    "def get_route_data(data_file): \n",
    "\t\"\"\"\n",
    "\tExtract the number of complete passes, incomplete passes, touchdowns, and interceptions \n",
    "\tfrom a pass chart. \n",
    "\t\"\"\"\n",
    "\twith open(data_file) as _file: \n",
    "\t\tdata = json.load(_file)\n",
    "\t\t_file.close()\n",
    "\tn_receptions = data[\"receptions\"]\n",
    "\tn_touchdowns = data[\"touchdowns\"]\n",
    "\n",
    "\treturn (n_receptions, n_touchdowns)\n",
    "\n",
    "def get_image(folder, data_file):\n",
    "\t\"\"\"\n",
    "\tIf cleaned image exists, return the file path to the image, \n",
    "\totherwise return none.\n",
    "\t\"\"\"\n",
    "\timages_path = os.sep.join(folder.split(os.sep)[:-1]) + os.sep + \"images\" \n",
    "\timage_file = images_path + os.sep + data_file.split(\".\")[0] + \".jpeg\"\n",
    "\tif not os.path.exists(image_file):\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\treturn image_file\n",
    "\n",
    "def get_game_data(data_file):\n",
    "\t\"\"\"\n",
    "\tExtract player name, team, and game ID from the data corresponding to a pass chart image.\n",
    "\t\"\"\"\t\n",
    "\twith open(data_file) as _file: \n",
    "\t\tdata = json.load(_file)\n",
    "\t\t_file.close()\n",
    "\tname = data[\"firstName\"] + \" \" + data[\"lastName\"]\n",
    "\tteam = data[\"team\"]\n",
    "\tgame_id = data[\"gameId\"]\n",
    "\tposition = data[\"position\"]\n",
    "\tweek = data_file.split(os.sep)[-3]\n",
    "\treturn (name, team, game_id, week, position)\n",
    "\n",
    "def write_route_locations(image, data, routes):\n",
    "\t\"\"\"\n",
    "\tWrite player, team, and game information, and locations of all passes to a .csv file.\n",
    "\t\"\"\"\n",
    "\t(n_route, n_td) = get_route_data(data)\n",
    "\t(name,team, game_id, week, position) = get_game_data(data)\n",
    "\tn_total = n_route\n",
    "\n",
    "\troute_cols = [\"route_type\", \"x\", \"y\"]\n",
    "\tgame_cols = [\"game_id\", \"team\", \"week\", \"name\", 'position']\n",
    "\troute_df = pd.DataFrame(columns = route_cols)\n",
    "\n",
    "\tif (image is None): \n",
    "\t\trows_route = pd.DataFrame([[\"NAN\", None, None]]*n_route, \n",
    "\t\t\tcolumns = route_cols)\n",
    "\t\troute_df = route_df.append([rows_route])\n",
    "\t\tgame_df = pd.DataFrame([[game_id, team, week, name, position]]*route_df.shape[0], \n",
    "\t\t\tcolumns = game_cols)\n",
    "\t\tdf = pd.concat([game_df, route_df.reset_index(drop=True)], axis=1)\n",
    "\t\troutes = routes.append(df)\n",
    "\t\treturn routes\n",
    "\n",
    "\tif n_total != 0: \n",
    "\t\trows_route = map_route_locations(image,n_td)\n",
    "\t\troute_df = route_df.append(rows_route)\n",
    "\n",
    "\tgame_df = pd.DataFrame([[game_id, team, week, name, position]]*route_df.shape[0], \n",
    "\t\tcolumns = game_cols)\n",
    "\n",
    "\tdf = pd.concat([game_df, route_df.reset_index(drop=True)], axis=1)\n",
    "\troutes = routes.append(df)\n",
    "\treturn routes\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\tclean_path = \"Cleaned_Route_Charts\"\n",
    "\troutes = pd.DataFrame(columns = [\"game_id\", \"team\", \"week\", \"name\", \"position\", \"route_type\", \"x\", \"y\"])\n",
    "\n",
    "\troute_chart_folders = [folder[0] for folder in os.walk(clean_path)]\n",
    "\tdata_folders = [folder for folder in route_chart_folders if folder.split(os.sep)[-1] == \"data\"]\n",
    "\n",
    "\t# td.to_csv('td_points.csv',index=False)\n",
    "\ttd = pd.read_csv('td_points.csv')\n",
    "\ttd_points = np.array(td[['x_coord','y_coord']])\n",
    "    \n",
    "\tprint(\"Extracting route locations...\")\n",
    "\tfor folder in data_folders:\n",
    "\t\tif ('2017' in folder):\n",
    "# \t\t\tprint(folder)\n",
    "\t\t\tdata = os.listdir(folder)\n",
    "\t\t\tprint(folder)\n",
    "\t\t\tfor data_file in data:\n",
    "\t\t\t\tif not data_file.startswith(\".\"): \n",
    "\t\t\t\t\tprint(data_file)\n",
    "\t\t\t\t\timage = get_image(folder, data_file)\n",
    "\t\t\t\t\troutes = write_route_locations(image, os.path.join(folder, data_file), routes)\n",
    "\troutes.to_csv(\"route_locations_sansTD_2017.csv\", index=False, header=True)\n",
    "\tprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
